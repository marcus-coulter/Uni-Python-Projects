{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here, each node on the left represents an input feature, the connecting lines represent\n",
    "the learned coefficients, and the node on the right represents the output, which is a\n",
    "weighted sum of the inputs.\n",
    "\n",
    "2. This model has a lot more coefficients (also called weights) to learn: there is one\n",
    "between every input and every hidden unit (which make up the hidden layer), and\n",
    "one between every unit in the hidden layer and the output.\n",
    "\n",
    "3. Computing a series of weighted sums is mathematically the same as computing just\n",
    "one weighted sum, so to make this model truly more powerful than a linear model,\n",
    "we need one extra trick. After computing a weighted sum for each hidden unit, a\n",
    "nonlinear function is applied to the result—usually the rectifying nonlinearity (also\n",
    "known as rectified linear unit or relu) or the tangens hyperbolicus (tanh). The result of\n",
    "this function is then used in the weighted sum that computes the output, ŷ. The two\n",
    "functions are visualized in the following Figure. The relu cuts off values below zero, while tanh\n",
    "saturates to –1 for low input values and +1 for high input values. Either nonlinear\n",
    "function allows the neural network to learn much more complicated functions than a\n",
    "linear model could:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the small neural network pictured in the first figure, the full formula for computing ŷ in the case of regression would be (when using a tanh nonlinearity):   \n",
    "h[0] = tanh(w[0, 0] * x[0] + w[1, 0] * x[1] + w[2, 0] * x[2] + w[3, 0] * x[3] + b[0])   \n",
    "h[1] = tanh(w[0, 1] * x[0] + w[1, 1] * x[1] + w[2, 1] * x[2] + w[3, 1] * x[3] + b[1])   \n",
    "h[2] = tanh(w[0, 2] * x[0] + w[1, 2] * x[1] + w[2, 2] * x[2] + w[3, 2] * x[3] + b[2])   \n",
    "ŷ = v[0] * h[0] + v[1] * h[1] + v[2] * h[2] + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **w** are the weights between the input **x** and the hidden layer **h**, and **v** are the\n",
    "weights between the hidden layer **h** and the output ŷ. The weights **v** and **w** are learned\n",
    "from data, **x** are the input features, ŷ is the computed output, and **h** are intermediate\n",
    "computations. An important parameter that needs to be set by the user is the number\n",
    "of nodes in the hidden layer. This can be as small as 10 for very small or simple datasets\n",
    "and as big as 10,000 for very complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having large neural networks made up of many of these layers of computation is\n",
    "what inspired the term “deep learning.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data used here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the data **Avila** from UCI: https://archive.ics.uci.edu/ml/datasets/Avila#. The Avila data set has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. In this lab, the‘avila-tr.txt'data is used. For your convenience, I have pre-processed an 'CSV' file in the Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS DISTRIBUTION (training set)\n",
    "\n",
    "A: 4286 \n",
    "\n",
    "B: 5 \n",
    "\n",
    "C: 103 \n",
    "\n",
    "D: 352 \n",
    "\n",
    "E: 1095 \n",
    "\n",
    "F: 1961 \n",
    "\n",
    "G: 446 \n",
    "\n",
    "H: 519 \n",
    "\n",
    "I: 831 \n",
    "\n",
    "W: 44 \n",
    "\n",
    "X: 522 \n",
    "\n",
    "Y: 266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1: intercolumnar distance \n",
    "\n",
    "F2: upper margin \n",
    "\n",
    "F3: lower margin \n",
    "\n",
    "F4: exploitation \n",
    "\n",
    "F5: row number \n",
    "\n",
    "F6: modular ratio \n",
    "\n",
    "F7: interlinear spacing \n",
    "\n",
    "F8: weight \n",
    "\n",
    "F9: peak number \n",
    "\n",
    "F10: modular ratio/ interlinear spacing \n",
    "\n",
    "Class: A, B, C, D, E, F, G, H, I, W, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Papers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. DeÂ Stefano, M. Maniaci, F. Fontanella, A. ScottoÂ diÂ Freca, \n",
    "Reliable writer identification in medieval manuscripts through page layout features: The 'Avila' Bible case, Engineering Applications of Artificial Intelligence, Volume 72, 2018, pp. 99-110. \n",
    "\n",
    "C. De Stefano, F. Fontanella, M. Maniaci and A. Scotto di Freca, 'A Method for Scribe Distinction in Medieval Manuscripts Using Page Layout Features', Lecture Notes in Computer Science, G. Maino and G. Foresti (eds.), Springer-Verlag, vol. 6978, pp. 393-402."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (10430, 11)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.165620</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>0.483299</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.273364</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.929823</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.436060</td>\n",
       "      <td>1.465940</td>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>-0.783147</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.439463</td>\n",
       "      <td>-0.081827</td>\n",
       "      <td>-0.888236</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>0.582939</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.583590</td>\n",
       "      <td>-0.721442</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>1.051693</td>\n",
       "      <td>0.594169</td>\n",
       "      <td>-0.533994</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229043</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>0.082634</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.148790</td>\n",
       "      <td>0.635431</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0  0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1  0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2 -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3  0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4  0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "\n",
       "         F8        F9       F10 Class  \n",
       "0  0.929823  0.251173  0.159345     A  \n",
       "1  0.636203  0.282354  0.515587     A  \n",
       "2 -0.888236 -0.123005  0.582939     A  \n",
       "3  1.051693  0.594169 -0.533994     A  \n",
       "4  0.051062  0.032902 -0.086652     F  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and show the basic information\n",
    "data=pd.read_csv(\"avila-tr.csv\")\n",
    "print('Data size: (%.f, %.f)\\n' % data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the Multi-Layer Perceptron model and its parameters\n",
    "We will use the multi-layer percepton to understand the basic usage of artificial neural network models. Class [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation. MLPClassifier has many parameters to configure. The effects of some important parameters have been discussed in our lecture, e.g., activation functions, number of hidden layers, number of units in a hidden layer, gradient descent, regularization, etc. So, in this workshop we would like to empirically study these parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic usage of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7584 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify features and the target\n",
    "X = data.drop(['Class'], axis = 'columns')\n",
    "y = data['Class']\n",
    "\n",
    "# Split the dataset into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Training the MLPClassifier with the default parameters (random_state=42)\n",
    "clf = MLPClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Output the accuracy on training data and test data respectively\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.4f \\n' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=42)\n",
      "\n",
      "# of layers (including the input layer): 3\n",
      "\n",
      "MLP structure: 10 X 100 X 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the learned MLP model\n",
    "print(clf)\n",
    "print('\\n# of layers (including the input layer): %.f\\n' % clf.n_layers_)\n",
    "print('MLP structure: %.f X %.f X %.f\\n' % (X.shape[1], clf.get_params()['hidden_layer_sizes'][0], clf.n_outputs_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use 10-fold cross validation to report a more robust testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy range for Multi-layer Perceptron: [0.7574, 0.7862]; mean: 0.7743; std: 0.0082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use 10-fold cross validation to validate the model\n",
    "clf = MLPClassifier(random_state=42)\n",
    "scores_mlp_default = cross_val_score(clf, X, y, cv=10, verbose=1)\n",
    "print('Accuracy range for Multi-layer Perceptron: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores_mlp_default.min(), scores_mlp_default.max(), scores_mlp_default.mean(), scores_mlp_default.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Increase the number of hidden units\n",
    "Here, we draw a figure to report the testing accuray with differnt number of hidden units [10,20,30,40,50,60,70,80,90,100]. The parameter 'hidden_layer_sizes' accepts a list of numbers specifying the number of units in each hidden layer. We plot the relationship between the parameter and the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number of hidden units, we use 10-fold cross validation to report the testing accuracy.\n",
    "# N.B.: The execution time is relatively long (around 5 minutes). This is to let you experience the intenstive computaiton required by artificial neural network models.\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "hidden_unit_numbers = [[10],[20],[30],[40],[50],[60],[70],[80],[90],[100]]\n",
    "for i in hidden_unit_numbers:\n",
    "    clf_mlp = MLPClassifier(hidden_layer_sizes=i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10, verbose=1)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.errorbar(hidden_unit_numbers, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.xlabel('Size of hidden units')\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that the accuracy increases when the number of units in the hidden layer increases. The reason is the a model with a bigger number of hiden layer units has a higher complexity to capture the information in data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1. Number of hidder layers\n",
    "Set the number of hidden layers as two, and each has 100 units. Please report the accuracy score and compare it with the single hidden layer case mentioend above. Note that the execution time for this task is relative long. To track the progress of the execution, you could set the verbose parameter in the cross_val_score method as 'verbose=1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a MLP model with two hidden layers\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is the dataset you are working with\n",
    "# Specify features and the target\n",
    "X = data.drop(['Class'], axis='columns')\n",
    "y = data['Class']\n",
    "\n",
    "# Split the dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. Training the MLPClassifier with a single hidden layer (from the previous task)\n",
    "clf_single_layer = MLPClassifier(hidden_layer_sizes=(100), random_state=42)\n",
    "clf_single_layer.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy for the single hidden layer\n",
    "y_pred_single_layer = clf_single_layer.predict(X_test)\n",
    "accuracy_single_layer = accuracy_score(y_test, y_pred_single_layer)\n",
    "print('Accuracy with a single hidden layer (100 units): %.4f' % accuracy_single_layer)\n",
    "\n",
    "# Perform 10-fold cross-validation for the single hidden layer\n",
    "scores_single_layer_cv = cross_val_score(clf_single_layer, X, y, cv=10, verbose=1)\n",
    "print('Cross-validation results for single hidden layer: [%.4f, %.4f]; mean: %.4f; std: %.4f'\n",
    "      % (scores_single_layer_cv.min(), scores_single_layer_cv.max(), scores_single_layer_cv.mean(), scores_single_layer_cv.std()))\n",
    "\n",
    "# 2. Training the MLPClassifier with two hidden layers (100 units each)\n",
    "clf_two_layers = MLPClassifier(hidden_layer_sizes=(100, 100), random_state=42)\n",
    "clf_two_layers.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy for the two hidden layers\n",
    "y_pred_two_layers = clf_two_layers.predict(X_test)\n",
    "accuracy_two_layers = accuracy_score(y_test, y_pred_two_layers)\n",
    "print('Accuracy with two hidden layers (100 units each): %.4f' % accuracy_two_layers)\n",
    "\n",
    "# Perform 10-fold cross-validation for the two hidden layers\n",
    "clf_two_layers_cv = MLPClassifier(hidden_layer_sizes=(100, 100), random_state=42)\n",
    "scores_two_layers_cv = cross_val_score(clf_two_layers_cv, X, y, cv=10, verbose=1)\n",
    "print('Cross-validation results for two hidden layers: [%.4f, %.4f]; mean: %.4f; std: %.4f'\n",
    "      % (scores_two_layers_cv.min(), scores_two_layers_cv.max(), scores_two_layers_cv.mean(), scores_two_layers_cv.std()))\n",
    "\n",
    "# 3. Plot the comparison of single vs two hidden layers\n",
    "hidden_unit_configs = ['Single Layer (100)', 'Two Layers (100, 100)']\n",
    "cv_means = [scores_single_layer_cv.mean(), scores_two_layers_cv.mean()]\n",
    "cv_stds = [scores_single_layer_cv.std(), scores_two_layers_cv.std()]\n",
    "\n",
    "plt.errorbar(hidden_unit_configs, cv_means, yerr=cv_stds, marker='o', label='Accuracy')\n",
    "plt.xlabel('Hidden Layer Configuration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.title('Comparison of Single vs Two Hidden Layers')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Choose solver for the learning process\n",
    "As discussed in our lecture, we can use gradient descent methods (standard gradient and stochastic gradient descent) to learn weights for the error minimization problem. Moreover, we can have other solvers for the optimization problem. Here, we draw a figure to report the accuray with differnt solvers. The parameter 'solver' can take values from ['lbfgs','sgd', 'adam']. 'sgd' represents stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different solvers\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "for i in solvers:\n",
    "    clf_mlp = MLPClassifier(solver=i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.bar(solvers, cv_scores, yerr=cv_scores_std, label='Accuracy')\n",
    "plt.xlabel('Solvers')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that sgd doesn't perform as well as the other two solvers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2. Activation functions\n",
    "It can be seen above that the default activation function is 'ReLU'. As we discussed in our lecture, we could have different types of activation functions. Please try the possible functions 'identity’, ‘logistic’, ‘tanh’, and ‘relu’ provided by the API. Draw a figure to report the accuray with differnt activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different activation functions\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of activation functions to test\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Store the mean accuracy and standard deviation for each activation function\n",
    "cv_means = []\n",
    "cv_stds = []\n",
    "\n",
    "# Loop over each activation function\n",
    "for activation in activation_functions:\n",
    "    print(f\"Evaluating MLP with {activation} activation...\")\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100, 100), activation=activation, random_state=42)\n",
    "    \n",
    "    # Perform 10-fold cross-validation\n",
    "    scores = cross_val_score(clf, X, y, cv=10, verbose=1)\n",
    "    \n",
    "    # Append the mean accuracy and standard deviation\n",
    "    cv_means.append(scores.mean())\n",
    "    cv_stds.append(scores.std())\n",
    "\n",
    "# Plot the results\n",
    "plt.errorbar(activation_functions, cv_means, yerr=cv_stds, marker='o', label='Accuracy')\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.5, 1.0)  # Adjust the y-axis limit to display accuracy clearly\n",
    "plt.title('Comparison of Activation Functions in MLP')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use different values of alpha\n",
    "The parameter alpha is the L2 penalty (regularization term) to overcome the overfitting issue. It balance the error caused the data and that by the model structure (number of weights). \n",
    "Here, please draw a figure to report the accuray with differnt values of alpha [0.0001,0.001,0.01, 0.1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different regulaization parameters\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "alphas = [0.0001,0.001,0.01, 0.1,1]\n",
    "for i in alphas:\n",
    "    clf_mlp = MLPClassifier(alpha=i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.errorbar(alphas, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylim([0.6, 0.85])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that when alpha increases, the prediction accuracy drops, showing that the overfitting issue of the model on this dataset is not a big problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task3. Increase the number of iterations\n",
    "This is related to the early stopping technique we mentioned in the lecture. Please explore when is good enough to stop the iteration of weight updating. Please draw a figure to report the accuray with differnt number of iterations [200,400,600,800,1000]. The parameter 'max_iter' can specify this setting. Note that the execution time for this task is relative long. To track the progress of the execution, you could set the verbose parameter in the cross_val_score method as 'verbose=1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different number of iterations. Plot the relationship between the performance and the number of iterations.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of different numbers of iterations to test\n",
    "iteration_numbers = [200, 400, 600, 800, 1000]\n",
    "\n",
    "# Store the mean accuracy and standard deviation for each number of iterations\n",
    "cv_means = []\n",
    "cv_stds = []\n",
    "\n",
    "# Loop over each number of iterations\n",
    "for max_iter in iteration_numbers:\n",
    "    print(f\"Evaluating MLP with {max_iter} iterations...\")\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=max_iter, random_state=42)\n",
    "    \n",
    "    # Perform 10-fold cross-validation\n",
    "    scores = cross_val_score(clf, X, y, cv=10, verbose=1)\n",
    "    \n",
    "    # Append the mean accuracy and standard deviation\n",
    "    cv_means.append(scores.mean())\n",
    "    cv_stds.append(scores.std())\n",
    "\n",
    "# Plot the results\n",
    "plt.errorbar(iteration_numbers, cv_means, yerr=cv_stds, marker='o', label='Accuracy')\n",
    "plt.xlabel('Number of Iterations (max_iter)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.5, 1.0)  # Adjust the y-axis limit to display accuracy clearly\n",
    "plt.title('Effect of Number of Iterations on MLP Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with other classification models\n",
    "### Task4. Compare the results with Naive Bayes (GaussianNB) and K-Nearest Neighbors (K=1)\n",
    "Compare their accuracy scores and use t test to show if their perofrmance has siginficantly different with significance level 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare with the two models we used before\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "\n",
    "# Initialize classifiers\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=200, random_state=42)\n",
    "nb_clf = GaussianNB()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# 1. Perform 10-fold cross-validation for each model\n",
    "print(\"Evaluating MLP...\")\n",
    "mlp_scores = cross_val_score(mlp_clf, X, y, cv=10, verbose=1)\n",
    "print(\"Evaluating Naive Bayes...\")\n",
    "nb_scores = cross_val_score(nb_clf, X, y, cv=10, verbose=1)\n",
    "print(\"Evaluating K-Nearest Neighbors (K=1)...\")\n",
    "knn_scores = cross_val_score(knn_clf, X, y, cv=10, verbose=1)\n",
    "\n",
    "# Report the mean accuracy for each model\n",
    "print(\"\\nAccuracy Scores:\")\n",
    "print(f\"MLP Accuracy: {mlp_scores.mean():.4f} ± {mlp_scores.std():.4f}\")\n",
    "print(f\"Naive Bayes Accuracy: {nb_scores.mean():.4f} ± {nb_scores.std():.4f}\")\n",
    "print(f\"K-Nearest Neighbors (K=1) Accuracy: {knn_scores.mean():.4f} ± {knn_scores.std():.4f}\")\n",
    "\n",
    "# 2. Perform paired t-tests to compare accuracy scores\n",
    "# Compare MLP vs Naive Bayes\n",
    "t_stat_mlp_nb, p_value_mlp_nb = stats.ttest_rel(mlp_scores, nb_scores)\n",
    "# Compare MLP vs KNN\n",
    "t_stat_mlp_knn, p_value_mlp_knn = stats.ttest_rel(mlp_scores, knn_scores)\n",
    "# Compare Naive Bayes vs KNN\n",
    "t_stat_nb_knn, p_value_nb_knn = stats.ttest_rel(nb_scores, knn_scores)\n",
    "\n",
    "# Significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# 3. Report t-test results\n",
    "print(\"\\nT-test Results (significance level 0.05):\")\n",
    "print(f\"MLP vs Naive Bayes: t-stat = {t_stat_mlp_nb:.4f}, p-value = {p_value_mlp_nb:.4f} -> {'Significant' if p_value_mlp_nb < alpha else 'Not Significant'}\")\n",
    "print(f\"MLP vs KNN: t-stat = {t_stat_mlp_knn:.4f}, p-value = {p_value_mlp_knn:.4f} -> {'Significant' if p_value_mlp_knn < alpha else 'Not Significant'}\")\n",
    "print(f\"Naive Bayes vs KNN: t-stat = {t_stat_nb_knn:.4f}, p-value = {p_value_nb_knn:.4f} -> {'Significant' if p_value_nb_knn < alpha else 'Not Significant'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
